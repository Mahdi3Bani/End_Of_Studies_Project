{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive frequentist approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 7: 2, 9: 3, 10: 4, 11: 5, 12: 6, 13: 7, 14: 8, 15: 9, 16: 10, 18: 11, 22: 12, 23: 13, 24: 14, 25: 15, 28: 16, 29: 17, 30: 18, 34: 19, 35: 20, 36: 21, 37: 22, 38: 23, 39: 24, 40: 25, 41: 26, 42: 27, 43: 28, 44: 29, 45: 30, 46: 31, 47: 32, 48: 33, 49: 34, 50: 35, 51: 36, 52: 37, 53: 38, 54: 39, 55: 40, 56: 41, 57: 42, 58: 43, 59: 44, 60: 45, 61: 46, 62: 47, 63: 48, 64: 49, 65: 50, 66: 51, 67: 52, 69: 53, 70: 54, 71: 55, 72: 56, 73: 57, 74: 58, 75: 59, 77: 60, 78: 61, 79: 62, 80: 63, 88: 64, 89: 65, 90: 66, 91: 67, 92: 68, 93: 69, 94: 70, 95: 71, 96: 72, 97: 73, 98: 74, 99: 75, 100: 76, 101: 77, 102: 78, 103: 79, 104: 80, 105: 81, 106: 82, 107: 83, 108: 84, 110: 85, 112: 86, 113: 87, 114: 88, 117: 89, 118: 90, 119: 91, 121: 92, 122: 93, 123: 94, 124: 95, 125: 96, 126: 97, 127: 98, 128: 99, 129: 100, 130: 101, 131: 102, 132: 103, 133: 104, 134: 105, 135: 106, 136: 107, 138: 108, 139: 109, 140: 110, 141: 111, 142: 112, 143: 113, 144: 114, 145: 115, 148: 116, 152: 117, 154: 118, 156: 119, 157: 120, 158: 121, 159: 122, 160: 123, 161: 124, 162: 125, 163: 126, 164: 127, 165: 128, 166: 129, 167: 130, 168: 131, 169: 132, 170: 133, 171: 134, 172: 135, 173: 136, 174: 137, 175: 138, 176: 139, 177: 140, 178: 141, 179: 142, 180: 143, 181: 144, 182: 145, 183: 146, 184: 147, 185: 148, 186: 149, 187: 150, 188: 151, 189: 152, 190: 153, 192: 154, 195: 155, 197: 156, 199: 157, 200: 158, 203: 159, 204: 160, 205: 161, 206: 162, 207: 163, 208: 164, 209: 165, 210: 166, 211: 167, 212: 168, 213: 169, 214: 170, 215: 171, 216: 172, 218: 173, 219: 174, 220: 175, 221: 176, 222: 177, 223: 178, 224: 179, 225: 180, 226: 181, 227: 182, 228: 183, 229: 184, 230: 185, 231: 186, 232: 187, 233: 188, 234: 189, 235: 190, 236: 191, 237: 192, 238: 193, 239: 194, 240: 195, 241: 196, 242: 197, 243: 198, 244: 199, 248: 200, 249: 201, 250: 202, 252: 203, 257: 204, 258: 205, 259: 206, 260: 207, 261: 208, 262: 209, 263: 210, 264: 211, 265: 212, 267: 213, 268: 214, 270: 215, 271: 216, 272: 217, 273: 218, 274: 219, 275: 220, 278: 221, 280: 222, 281: 223, 283: 224, 284: 225, 285: 226, 286: 227, 287: 228, 288: 229, 289: 230, 290: 231, 291: 232, 292: 233, 293: 234, 294: 235, 295: 236, 298: 237, 299: 238, 300: 239, 301: 240, 302: 241, 303: 242, 304: 243, 306: 244, 307: 245, 308: 246, 309: 247, 310: 248, 311: 249, 312: 250, 313: 251, 314: 252, 315: 253, 316: 254, 317: 255, 318: 256, 319: 257, 320: 258, 321: 259, 322: 260, 323: 261, 324: 262, 325: 263, 326: 264, 327: 265, 328: 266, 329: 267, 330: 268, 331: 269, 332: 270, 333: 271, 334: 272, 335: 273, 336: 274, 338: 275, 339: 276, 340: 277}\n"
     ]
    }
   ],
   "source": [
    "malwares = []\n",
    "\n",
    "\n",
    "\n",
    "lengths=[]\n",
    "with open('../archive/api/1000_calls.txt') as f :\n",
    "    for line in f:\n",
    "        l=line.split(',')\n",
    "        l=[int(x) for x in l]\n",
    "        malwares.append(np.array(l))\n",
    "\n",
    "\n",
    "# we want our words to fill an interval of integers [0... something[\n",
    "def translate_to_normal(malwares) :\n",
    "    values=set(np.concatenate(malwares))\n",
    "    values=list(values)\n",
    "    dic={}\n",
    "    for i in range(len(values)) :\n",
    "        dic[values[i]]=i\n",
    "    print(dic)\n",
    "    return [np.array([dic[x] for x in row]) for row in malwares]\n",
    "\n",
    "malwares = translate_to_normal(malwares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "\n",
    "with open('../archive/labels.txt') as f :\n",
    "    for line in f:\n",
    "        labels.append(line.split('\\n')[0])\n",
    "\n",
    "uniques = np.unique(np.array(labels),return_counts=True)\n",
    "\n",
    "dic={}\n",
    "for x,i in zip(uniques[0],range(8)) :\n",
    "    dic[x]=i\n",
    "\n",
    "labels=np.array([dic[x] for x in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [m.size for m in malwares]\n",
    "indices=list(range(len(malwares)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([6.83e+03, 9.70e+01, 3.50e+01, 3.10e+01, 1.80e+01, 1.10e+01,\n",
       "        2.10e+01, 7.00e+00, 1.20e+01, 1.20e+01, 7.00e+00, 7.00e+00,\n",
       "        3.00e+00, 2.00e+00, 3.00e+00, 2.00e+00, 6.00e+00, 1.00e+00,\n",
       "        0.00e+00, 2.00e+00]),\n",
       " array([1.00000000e+01, 8.82305500e+04, 1.76451100e+05, 2.64671650e+05,\n",
       "        3.52892200e+05, 4.41112750e+05, 5.29333300e+05, 6.17553850e+05,\n",
       "        7.05774400e+05, 7.93994950e+05, 8.82215500e+05, 9.70436050e+05,\n",
       "        1.05865660e+06, 1.14687715e+06, 1.23509770e+06, 1.32331825e+06,\n",
       "        1.41153880e+06, 1.49975935e+06, 1.58797990e+06, 1.67620045e+06,\n",
       "        1.76442100e+06]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(malwares))\n",
    "plt.hist(lengths,bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restrict to sequences of api calls of a reasonable size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4322\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths=[x for x in lengths if x<2000 and x>100]\n",
    "print(len(lengths))\n",
    "plt.hist(lengths,bins=20)\n",
    "\n",
    "indices_train_test=[x for x in indices if len(malwares[x])>100 and len(malwares[x])<2000] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset in a train set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(indices_train_test, alpha) :\n",
    "    #alpha is the probability to lie in the test set\n",
    "    indices_test=[]\n",
    "    indices_train=[]\n",
    "    for index in indices_train_test :\n",
    "        u = np.random.rand()\n",
    "        if u < alpha : \n",
    "            indices_test.append(index)\n",
    "        else :\n",
    "            indices_train.append(index)\n",
    "    return indices_test, indices_train\n",
    "\n",
    "indices_test, indices_train = split_train_test(indices_train_test, .20)\n",
    "\n",
    "malwares_test, malwares_train = [malwares[i] for i in indices_test] , [malwares[i] for i in indices_train]\n",
    "\n",
    "labels_test, labels_train = [labels[i] for i in indices_test] , [labels[i] for i in indices_train]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the labels in the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([157, 544, 586, 435, 421, 519, 299, 476]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(np.array(labels_train),return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each malware let us record the frequencies of each possible api call in a vector of length 278:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_naive_statistical_test(indices,len_of_range):\n",
    "    record = []\n",
    "    for i in indices :\n",
    "        vec=[]\n",
    "        malware=np.array(malwares[i])\n",
    "        for var in range(len_of_range) :\n",
    "            vec.append(np.sum(np.equal(malware,var)))\n",
    "        record.append(vec)\n",
    "    return np.array(record, dtype=float)\n",
    "\n",
    "naive_train=most_naive_statistical_test(indices_train,278)\n",
    "naive_test=most_naive_statistical_test(indices_test,278)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the sequences have variable size it seems natural to normalise these vectors of length 278."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_train/=naive_train.std(axis=1)[:,None]\n",
    "naive_test/=naive_test.std(axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each of our vector has non negative coordinates, and lie on the sphere of radius 1 in the 278 dimensional space. This dimension is too large to use the usual geometric tools like K-Means and KNN (they don't behave well in large dimensions). So let us reduce the dimension :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23015396 0.3938266  0.49967131 0.5599534  0.60339495 0.64133237\n",
      " 0.67347146 0.70302553 0.72776238 0.74909727 0.76677743 0.7830551 ]\n"
     ]
    }
   ],
   "source": [
    "kept_dimensions = 12\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=kept_dimensions)\n",
    "pca.fit(naive_train)\n",
    "print(np.cumsum(pca.explained_variance_ratio_))    \n",
    "\n",
    "pca_train = pca.transform(naive_train)\n",
    "pca_test  = pca.transform(naive_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply K-means to see whether the geometry we obtained allows to clusterize the malwares according to their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:0\n",
      "Distributions of classes in the clusters:\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 56,  19, 232,  37,  15,  34,  35,  48]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 38, 244, 175, 154, 186, 252,  89, 212]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 44, 104,  30,  77,  83,  97,  29,  81]))\n",
      "(array([1, 2, 4, 5, 6, 7]), array([49,  1,  4, 10,  2, 19]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([10, 21, 90, 79, 29, 23, 40, 31]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 5,  8, 15, 18, 27, 14,  1, 12]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 1, 51, 14, 31, 44, 48, 52, 58]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 3, 48, 29, 39, 33, 41, 51, 15]))\n",
      "state:1\n",
      "Distributions of classes in the clusters:\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 1, 50, 13, 30, 41, 47, 50, 56]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 44, 107,  31,  75,  82,  99,  28,  83]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 38, 242, 174, 155, 187, 249,  90, 210]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 56,  19, 232,  37,  15,  34,  35,  48]))\n",
      "(array([1, 2, 4, 5, 6, 7]), array([49,  1,  4, 10,  2, 19]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 5,  8, 15, 18, 27, 14,  1, 12]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 3, 48, 30, 41, 37, 43, 52, 17]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([10, 21, 90, 79, 28, 23, 41, 31]))\n",
      "state:2\n",
      "Distributions of classes in the clusters:\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 56,  19, 230,  37,  15,  34,  35,  48]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 44, 104,  29,  77,  82,  96,  29,  81]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([10, 21, 92, 79, 28, 23, 42, 31]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 3, 48, 30, 39, 37, 43, 51, 16]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 38, 245, 176, 155, 187, 252,  90, 211]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 5,  7, 15, 18, 27, 14,  1, 13]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 1, 51, 13, 30, 41, 47, 49, 57]))\n",
      "(array([1, 2, 4, 5, 6, 7]), array([49,  1,  4, 10,  2, 19]))\n",
      "state:3\n",
      "Distributions of classes in the clusters:\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([10, 21, 92, 79, 28, 23, 42, 31]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 38, 245, 176, 155, 186, 252,  90, 211]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 3, 48, 30, 39, 37, 43, 51, 17]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 56,  19, 230,  37,  15,  34,  35,  48]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 1, 50, 13, 30, 41, 47, 49, 56]))\n",
      "(array([1, 2, 4, 5, 6, 7]), array([49,  1,  4, 10,  2, 19]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 44, 104,  29,  77,  82,  96,  29,  81]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 5,  8, 15, 18, 28, 14,  1, 13]))\n",
      "state:4\n",
      "Distributions of classes in the clusters:\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 56,  19, 232,  37,  15,  34,  35,  48]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 38, 242, 174, 155, 186, 248,  90, 210]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 3, 48, 30, 41, 37, 43, 52, 16]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 44, 107,  31,  75,  83, 100,  28,  83]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([10, 21, 90, 79, 28, 23, 42, 31]))\n",
      "(array([1, 2, 4, 5, 6, 7]), array([49,  1,  4, 10,  2, 19]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 1, 51, 13, 30, 41, 47, 49, 57]))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 5,  7, 15, 18, 27, 14,  1, 12]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def K_Means_naive( state ):\n",
    "    print(f\"state:{state}\")\n",
    "    print(\"Distributions of classes in the clusters:\")\n",
    "    kmeans = KMeans(n_clusters=8, random_state=state, n_init=20).fit(naive_train)\n",
    "    clusters=[[],[],[],[],[],[],[],[]]\n",
    "    for x in range(len(indices_train)):\n",
    "        clusters[kmeans.labels_[x]].append(labels[indices_train[x]])\n",
    "    for c in clusters :\n",
    "        print(np.unique(c,return_counts=True))\n",
    "\n",
    "for state in range(5) :\n",
    "    K_Means_naive( state )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** The naive method associated to K-Means does not allow to have an efficient clustering (in the sense that the clusters are very etherogeneous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(naive_train,[labels[i] for i in indices_train])\n",
    "pred=neigh.predict(naive_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's compare pred and true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5242937853107345\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(np.equal(pred,np.array([labels[i] for i in indices_test])))/len(indices_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Interestingly, frequencies already allow to have quite good predictions compares to a random prediction that would result in a 12.5% accuracy.  \n",
    "\n",
    "**Challenge**: do better !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using HMMs to associate coordinates to our malwares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['Adware', 'Backdoor', 'Downloader', 'Dropper', 'Spyware', 'Trojan',\n",
      "       'Virus', 'Worms'], dtype='<U10'), array([ 379, 1001, 1001,  891,  832, 1001, 1001, 1001]))\n"
     ]
    }
   ],
   "source": [
    "print(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Baum Welch algorithm to train HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Baum_Welch_Norm_step(a,b,init,obs) :\n",
    "    N=a.shape[0]\n",
    "    M=b.shape[0]\n",
    "    T=len(obs)\n",
    "    cs=[]\n",
    "\n",
    "    # compute the alphas\n",
    "    alphas=np.zeros([a.shape[0],len(obs)])\n",
    "    alpha=(b[obs[0],:].ravel())*(init.ravel())\n",
    "    #print(\"alpha : \",alpha)\n",
    "    c=np.sum(alpha)\n",
    "    #print(\"c = \",c)\n",
    "    cs.append(1/c)\n",
    "    alpha/=c\n",
    "    alphas[:,0]=alpha\n",
    "    #print(\"alphas : \",alphas)\n",
    "    for i in range(1,len(obs)) :\n",
    "        alpha= b[obs[i],:]*np.matmul(a,alpha)\n",
    "        #print(i,\"alpha =\", alpha)\n",
    "        c=np.sum(alpha)\n",
    "        #print(i,\"c =\", c)\n",
    "        cs.append(1/c)\n",
    "        alpha/=c\n",
    "        alphas[:,i]=alpha\n",
    "\n",
    "\n",
    "    # Compute the betas\n",
    "\n",
    "    betas=np.zeros([a.shape[0],T])\n",
    "    beta=np.ones(a.shape[0])*cs[T-1]\n",
    "    betas[:,T-1]=beta\n",
    "    for i in range(1,T-1) :\n",
    "        beta=np.matmul(b[obs[T-i],:]*beta,a)\n",
    "        beta*=cs[T-i-1]\n",
    "        betas[:,T-i-1]=beta\n",
    "\n",
    "\n",
    "    #Compute the lambdas\n",
    "    lambdas=np.zeros([N,N,T-1])\n",
    "    for s in range(T-1) :\n",
    "        lambdas[:,:,s]=np.transpose((betas[:,s+1]*b[obs[s+1],:])*np.transpose(a*alphas[:,s]))\n",
    "\n",
    "\n",
    "    #Compute the gammas\n",
    "    gammas=np.sum(lambdas, axis=0)\n",
    "\n",
    "    #Compute new B\n",
    "    sumgammas=np.sum(gammas,axis=1)\n",
    "    new_B=np.zeros([M,N])\n",
    "    for i in range(M) :\n",
    "        mask=np.array([o==i for o in obs[:-1] ])*1.0\n",
    "        new_B[i,:]=(np.sum(gammas*mask, axis=1)/sumgammas)\n",
    "\n",
    "    #Compute new A\n",
    "    sumlambd=np.sum(lambdas,axis=2)\n",
    "    new_A=sumlambd/sumgammas\n",
    "\n",
    "    #Compute new init\n",
    "    new_init=gammas[:,0]\n",
    "\n",
    "    #Compute log likehood\n",
    "    log_lik=-1*np.sum(np.log(np.array(cs)))\n",
    "\n",
    "    return new_A,new_B,new_init,log_lik\n",
    "\n",
    "\n",
    "def random_init_prob_cols(n_rows,n_cols) :\n",
    "    answer=np.random.randn(n_cols*n_rows).reshape((n_rows,n_cols))\n",
    "    answer=np.exp(answer)\n",
    "    answer/=np.sum(answer,axis=0)[None,:]\n",
    "    return answer\n",
    "\n",
    "def train_HMM_on_seq_of_api_calls(line_as_number,n_hidden, n_obs):\n",
    "\n",
    "    \n",
    "    est_A=random_init_prob_cols(n_hidden,n_hidden)\n",
    "    est_B=random_init_prob_cols(n_obs,n_hidden)\n",
    "    est_init=np.ones(n_hidden)/n_hidden\n",
    "\n",
    "    for _ in range(15) :\n",
    "        est_A,est_B,est_init,log_lik=Baum_Welch_Norm_step(est_A,est_B,est_init,line_as_number)\n",
    "        est_B = np.maximum(est_B,.000001)\n",
    "        est_B /= (est_B.sum(axis=0)[None,:])\n",
    "        #print(\"  ----->\",_, \" : \" ,log_lik)\n",
    "    \n",
    "    return est_A, est_B, est_init\n",
    "\n",
    "def log_lik(a,b,init,obs):\n",
    "    N=a.shape[0]\n",
    "    M=b.shape[0]\n",
    "    T=len(obs)\n",
    "    cs=[]\n",
    "\n",
    "    # compute the alphas\n",
    "    alphas=np.zeros([a.shape[0],len(obs)])\n",
    "    alpha=(b[obs[0],:].ravel())*(init.ravel())\n",
    "    #print(\"alpha : \",alpha)\n",
    "    c=np.sum(alpha)\n",
    "    #print(\"c = \",c)\n",
    "    cs.append(1/c)\n",
    "    alpha/=c\n",
    "    alphas[:,0]=alpha\n",
    "    #print(\"alphas : \",alphas)\n",
    "    for i in range(1,len(obs)) :\n",
    "        alpha= b[obs[i],:]*np.matmul(a,alpha)\n",
    "        #print(i,\"alpha =\", alpha)\n",
    "        c=np.sum(alpha)\n",
    "        #print(i,\"c =\", c)\n",
    "        cs.append(1/c)\n",
    "        alpha/=c\n",
    "        alphas[:,i]=alpha\n",
    "\n",
    "    log_lik=-1*np.sum(np.log(np.array(cs)))\n",
    "    return log_lik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each malware allows us to define a function from programs (in fact sequences of api calls) to $\\mathbb R$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hmm_f_for_row(row, n_hidden, n_obs):\n",
    "    a, b , init = train_HMM_on_seq_of_api_calls(row, n_hidden, n_obs)\n",
    "    init=np.ones(n_hidden)/n_hidden\n",
    "    def log_lik_hmm(other_row):\n",
    "        return log_lik(a,b,init,other_row)\n",
    "    return log_lik_hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class individual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class individual() :\n",
    "    def __init__(self, indices_for_sequence_of_malwares_train , print_details=False) :\n",
    "        self.indices=indices_for_sequence_of_malwares_train\n",
    "        self.representatives = [malwares_train[i] for i in self.indices] #2 per class (2 for the first class, then 2 for the second class etc.)\n",
    "        self.functions_associated_to_representatives=[]\n",
    "        self.frame=None\n",
    "        self.compute_frame()\n",
    "        self.print_details=print_details\n",
    "\n",
    "    def compute_coordinates(self) :\n",
    "        for row in self.representatives :\n",
    "            f_row = get_hmm_f_for_row(np.array(row), 20, 278 )\n",
    "            self.functions_associated_to_representatives.append(f_row)\n",
    "\n",
    "    def compute_embedded_image(self,malwares) :\n",
    "        log_liks = [[f(x) for f in self.functions_associated_to_representatives] for x in malwares]\n",
    "        log_liks=np.array(log_liks)\n",
    "        log_liks/=np.std(log_liks,axis=1)[:,None]\n",
    "        return log_liks\n",
    "        \n",
    "    def compute_frame(self) :\n",
    "        self.compute_coordinates()\n",
    "        \n",
    "        self.frame=self.compute_embedded_image(self.representatives)\n",
    "\n",
    "    def accuracy(self, n) :\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=6)\n",
    "        pca.fit(self.frame)\n",
    "        if self.print_details :\n",
    "            print(np.cumsum(pca.explained_variance_ratio_))\n",
    "        self.frame_pca=pca.transform(self.frame)\n",
    "        \n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "        neigh.fit(self.frame_pca,np.concatenate([i*np.ones(2,dtype=int) for i in range(8)]))\n",
    "\n",
    "        \n",
    "\n",
    "        def test(i) :\n",
    "            m=malwares_train[i]\n",
    "            coord_m=np.array([f(m) for f in self.functions_associated_to_representatives])\n",
    "            coord_m/=coord_m.std()\n",
    "            coord_m = pca.transform([coord_m])\n",
    "            p=neigh.predict(coord_m)\n",
    "            return  p[0] == labels_train[i] \n",
    "            \n",
    "        def statistics (n) :\n",
    "            part=0\n",
    "            for i in random.choices(list(range(len(malwares_train))), k=n) :\n",
    "                if i%100==0 : \n",
    "                    print(\"testing :\",i)\n",
    "                part+=test(i)\n",
    "            return part/n\n",
    "\n",
    "        return statistics(n)\n",
    "\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing : 3400\n",
      "testing : 3400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m) :\n\u001b[1;32m     18\u001b[0m     ind\u001b[38;5;241m=\u001b[39mrandom_individual()\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy on the 1000 first malwares :\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[84], line 56\u001b[0m, in \u001b[0;36mindividual.accuracy\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     53\u001b[0m         part\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mtest(i)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m part\u001b[38;5;241m/\u001b[39mn\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstatistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[84], line 53\u001b[0m, in \u001b[0;36mindividual.accuracy.<locals>.statistics\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m : \n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtesting :\u001b[39m\u001b[38;5;124m\"\u001b[39m,i)\n\u001b[0;32m---> 53\u001b[0m     part\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m part\u001b[38;5;241m/\u001b[39mn\n",
      "Cell \u001b[0;32mIn[84], line 42\u001b[0m, in \u001b[0;36mindividual.accuracy.<locals>.test\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m(i) :\n\u001b[1;32m     41\u001b[0m     m\u001b[38;5;241m=\u001b[39mmalwares_train[i]\n\u001b[0;32m---> 42\u001b[0m     coord_m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions_associated_to_representatives\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     43\u001b[0m     coord_m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39mcoord_m\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m     44\u001b[0m     coord_m \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform([coord_m])\n",
      "Cell \u001b[0;32mIn[84], line 42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m(i) :\n\u001b[1;32m     41\u001b[0m     m\u001b[38;5;241m=\u001b[39mmalwares_train[i]\n\u001b[0;32m---> 42\u001b[0m     coord_m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunctions_associated_to_representatives])\n\u001b[1;32m     43\u001b[0m     coord_m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39mcoord_m\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m     44\u001b[0m     coord_m \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform([coord_m])\n",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m, in \u001b[0;36mget_hmm_f_for_row.<locals>.log_lik_hmm\u001b[0;34m(other_row)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_lik_hmm\u001b[39m(other_row):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_lik\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mother_row\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 105\u001b[0m, in \u001b[0;36mlog_lik\u001b[0;34m(a, b, init, obs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#print(\"alphas : \",alphas)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(obs)) :\n\u001b[0;32m--> 105\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m b[obs[i],:]\u001b[38;5;241m*\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m#print(i,\"alpha =\", alpha)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     c\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(alpha)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Example :\n",
    "import random \n",
    "\n",
    "labels_train=np.array(labels_train)\n",
    "\n",
    "def get_random_genom() :\n",
    "    indices_of_representatives = []\n",
    "    for x in [dic[malware_type] for malware_type in uniques[0]] :\n",
    "        indices_of_malwares_of_type_x = [ i for i in range(len(malwares_train)) if ( labels_train[i]==x   ) and (len(malwares_train[i]<500))] #last condition to be deleted later\n",
    "        sample=random.sample(indices_of_malwares_of_type_x,2)\n",
    "        indices_of_representatives+=sample\n",
    "    return indices_of_representatives\n",
    "    \n",
    "def random_individual() :\n",
    "    return individual(get_random_genom())\n",
    "\n",
    "for i in range(10) :\n",
    "    ind=random_individual()\n",
    "    print(\"accuracy on the 1000 first malwares :\",ind.accuracy(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic algorithm to choose the frame\n",
    "\n",
    "We see the list of 16 indices of chosen malwares as the DNA of our individuals.\n",
    "\n",
    "We begin with 12 individuals and compute their accuracy on a test set.\n",
    "\n",
    "We keep only the two best individuals (the one that have the highest accuracy) \n",
    "\n",
    "We choose 10 new individuals (their children) as follows :\n",
    "\n",
    "    the DNA of a child is made by choosing one chromosom in the genom of its parents\n",
    "    4 of the chromosoms, chosen randomly are mutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_generation(generation ) :\n",
    "    accuracies = np.array([ind.accuracy(400) for ind in generation])\n",
    "    print(\"accuracies=\", accuracies)\n",
    "    sorted=np.sort(accuracies)\n",
    "    max_vals= sorted[-2:]\n",
    "    parents=[generation[i] for i in range(12) if accuracies[i] in max_vals]\n",
    "    answer=[parents[i] for i in range(2)]\n",
    "    \n",
    "    for i in range(10) :    \n",
    "        indices_mother=parents[0].indices\n",
    "        indices_father=parents[1].indices\n",
    "        indices_child=[]\n",
    "        for j in range(8) :\n",
    "            u=np.random.rand()\n",
    "            if u>.5 :\n",
    "                indices_child.append(indices_mother[2*j+1])\n",
    "            else :\n",
    "                indices_child.append(indices_mother[2*j])\n",
    "            u=np.random.rand()\n",
    "            if u>.5 :\n",
    "                indices_child.append(indices_father[2*j+1])\n",
    "            else :\n",
    "                indices_child.append(indices_father[2*j])\n",
    "        mutations = random.choices(list(range(16)),k=4)\n",
    "        random_genom = get_random_genom()\n",
    "        for j in mutations :\n",
    "            indices_child[j] = random_genom[j]\n",
    "        answer.append(individual(indices_child))\n",
    "    return answer\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def genetic(n_generations) :\n",
    "\n",
    "    # Choose 12 random individuals\n",
    "    generation =[]\n",
    "    for i in range(12) :\n",
    "        generation.append(random_individual())\n",
    "    print([ind.indices for ind in generation])\n",
    "    for g in range(n_generations) :\n",
    "        generation = next_generation(generation)\n",
    "        print(f\"------------------------------------- generation {g}\")\n",
    "        print([ind.indices for ind in generation])\n",
    "\n",
    "    return generation\n",
    "\n",
    "\n",
    "genetic(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Older material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2914 :  [False]\n",
      "1577 :  [False]\n",
      "1540 :  [False]\n",
      "1697 :  [ True]\n",
      "227 :  [ True]\n",
      "1428 :  [ True]\n",
      "2689 :  [ True]\n",
      "3062 :  [ True]\n",
      "2782 :  [False]\n",
      "2320 :  [False]\n",
      "279 :  [False]\n",
      "55 :  [ True]\n",
      "3404 :  [False]\n",
      "3388 :  [False]\n",
      "1380 :  [False]\n",
      "369 :  [ True]\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.accuracy(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying : \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(statistics(\u001b[38;5;241m200\u001b[39m))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m) :\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mtrying\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m, in \u001b[0;36mtrying\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m uniques[\u001b[38;5;241m0\u001b[39m] :\n\u001b[1;32m      7\u001b[0m     indices_of_malwares_of_type_x \u001b[38;5;241m=\u001b[39m [ i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(malwares)) \u001b[38;5;28;01mif\u001b[39;00m ( labels[i]\u001b[38;5;241m==\u001b[39mx  \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(malwares[i])\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m5000\u001b[39m ) ] \n\u001b[0;32m----> 8\u001b[0m     sample\u001b[38;5;241m=\u001b[39m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_of_malwares_of_type_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhyperparameter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m,sample)\n\u001b[1;32m     10\u001b[0m     representatives\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m[malwares[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sample]\n",
      "File \u001b[0;32m/usr/lib/python3.11/random.py:456\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    454\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    457\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m    458\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "def trying() :\n",
    "    import random \n",
    "    hyperparameter = 2\n",
    "    representatives = []\n",
    "    print (\"trying : \")\n",
    "    for x in uniques[0] :\n",
    "        indices_of_malwares_of_type_x = [ i for i in range(len(malwares)) if ( labels[i]==x  and len(malwares[i])<5000 ) ] \n",
    "        sample=random.sample(indices_of_malwares_of_type_x,hyperparameter)\n",
    "        print(x,\" : \",sample)\n",
    "        representatives+=[malwares[i] for i in sample]\n",
    "\n",
    "    \n",
    "    \n",
    "    count=0\n",
    "    functions_associated_to_representatives=[]\n",
    "    for row in representatives :\n",
    "        print(count)\n",
    "        count+=1\n",
    "        f_row = get_hmm_f_for_row(np.array(row), 20, 267 )\n",
    "        functions_associated_to_representatives.append(f_row)\n",
    "    \n",
    "    #8*hyperparameter points in a 8*hyperparameter dimensional space\n",
    "    \n",
    "    log_liks = [[f(x) for f in functions_associated_to_representatives] for x in representatives]\n",
    "    \n",
    "    log_liks=np.array(log_liks).T\n",
    "    \n",
    "    log_liks/=np.std(log_liks,axis=1)[:,None]\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=6)\n",
    "    pca.fit(log_liks)\n",
    "    print(np.cumsum(pca.explained_variance_ratio_))\n",
    "    \n",
    "    log_liks_pca=pca.transform(log_liks)\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    neigh = KNeighborsClassifier(n_neighbors=hyperparameter)\n",
    "    neigh.fit(log_liks_pca,np.concatenate([i*np.ones(hyperparameter,dtype=int) for i in range(8)]))\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def statistics (n) :\n",
    "        tot=0\n",
    "        tot_laxist=0\n",
    "        tot_severe=0\n",
    "        for i in range(n) :\n",
    "            if len(malwares[i])<20000 :\n",
    "                tot+=1\n",
    "                if i%20==0 : \n",
    "                    print(i)\n",
    "                laxist,severe =test(i)\n",
    "                tot_laxist+=laxist\n",
    "                tot_severe+=severe\n",
    "        return tot_laxist/tot, tot_severe/tot\n",
    "    \n",
    "    print(statistics(200))\n",
    "\n",
    "for i in range(10) :\n",
    "    trying()\n",
    "    print(\"-----------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an individual is a choice of hyperparameter*8 malwares\n",
    "# a generation is a choice of 10 individuals\n",
    "# for each generation we keep the best three individuals, and 7 children obtained by mixing the malwares in the individuals and changing randomly 4 of the malwares\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def genetic_search(n_generations) :\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uniques[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100/8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_liks=np.array(log_liks)\n",
    "log_liks_centered=np.array(log_liks) - np.array([ log_liks[i,i] for i in range(40)]) \n",
    "log_liks_normalized= log_liks_centered/np.min(log_liks,axis=1)[:,None]\n",
    "plt.imshow(log_liks_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malwares = malwares.dropna(subset='malware')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malwares.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.arange(malwares.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "random_choices = indexes[:1000]\n",
    "D= malwares.iloc[random_choices, 1:]\n",
    "malwares= malwares.iloc[:, 1:]\n",
    "\n",
    "len(np.unique(malwares.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "y=[]\n",
    "z=[]\n",
    "max_clust = 31\n",
    "for i in range(2,max_clust):\n",
    "    model = KMeans(n_clusters=i, random_state=0, n_init='auto')\n",
    "    model.fit(test)\n",
    "    y.append(model.inertia_)\n",
    "for i in range(2,max_clust):\n",
    "    model = KMeans(n_clusters=i, random_state=0, n_init='auto')\n",
    "    model.fit(randomised_test)\n",
    "    z.append(model.inertia_)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(2, max_clust), y, label='test')\n",
    "plt.plot(range(2, max_clust), z, label='randomised_test')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Choosing Number of Clusters')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\"\"\"\n",
    "plt.plot(range(2,max_clust),y)\n",
    "plt.plot(range(2,max_clust),z)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = malwares[malwares['malware'] == 1].iloc[:,1:101].to_numpy()\n",
    "print('unique test:',np.unique(test))\n",
    "print(np.unique(test).size)\n",
    "\n",
    "def transle_to_norm(s):\n",
    "    u = np.unique(s)\n",
    "    l_u = u.size\n",
    "    translator = dict()\n",
    "    for w,i in zip(u, range(l_u)):\n",
    "        translator[w]=i\n",
    "    translaed_s = [[translator[w] for w in row]for row in s]\n",
    "\n",
    "    return np.array(translaed_s), l_u\n",
    "\n",
    "x,l=transle_to_norm(test)\n",
    "print('x:',np.unique(x))\n",
    "print('l:',l)\n",
    "\n",
    "\n",
    "randomised_test = test.copy()\n",
    "print(type(randomised_test))\n",
    "print(test.shape)\n",
    "np.random.shuffle(randomised_test)\n",
    "print('test shape:', test.shape)\n",
    "#np.reshape(randomised_test,test.shape)\n",
    "print('randomised test shape:', randomised_test.shape)\n",
    "print('random:',randomised_test[:2])\n",
    "print('test:', test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Baum_Welch_Norm_step(a,b,init,obs) :\n",
    "    N=a.shape[0]\n",
    "    M=b.shape[0]\n",
    "    T=len(obs)\n",
    "    cs=[]\n",
    "\n",
    "    # compute the alphas\n",
    "    alphas=np.zeros([a.shape[0],len(obs)])\n",
    "    alpha=(b[obs[0],:].ravel())*(init.ravel())\n",
    "    #print(\"alpha : \",alpha)\n",
    "    c=np.sum(alpha)\n",
    "    #print(\"c = \",c)\n",
    "    cs.append(1/c)\n",
    "    alpha/=c\n",
    "    alphas[:,0]=alpha\n",
    "    #print(\"alphas : \",alphas)\n",
    "    for i in range(1,len(obs)) :\n",
    "        alpha= b[obs[i],:]*np.matmul(a,alpha)\n",
    "        #print(i,\"alpha =\", alpha)\n",
    "        c=np.sum(alpha)\n",
    "        #print(i,\"c =\", c)\n",
    "        cs.append(1/c)\n",
    "        alpha/=c\n",
    "        alphas[:,i]=alpha\n",
    "\n",
    "\n",
    "    # Compute the betas\n",
    "\n",
    "    betas=np.zeros([a.shape[0],T])\n",
    "    beta=np.ones(a.shape[0])*cs[T-1]\n",
    "    betas[:,T-1]=beta\n",
    "    for i in range(1,T-1) :\n",
    "        beta=np.matmul(b[obs[T-i],:]*beta,a)\n",
    "        beta*=cs[T-i-1]\n",
    "        betas[:,T-i-1]=beta\n",
    "\n",
    "\n",
    "    #Compute the lambdas\n",
    "    lambdas=np.zeros([N,N,T-1])\n",
    "    for s in range(T-1) :\n",
    "        lambdas[:,:,s]=np.transpose((betas[:,s+1]*b[obs[s+1],:])*np.transpose(a*alphas[:,s]))\n",
    "\n",
    "\n",
    "    #Compute the gammas\n",
    "    gammas=np.sum(lambdas, axis=0)\n",
    "\n",
    "    #Compute new B\n",
    "    sumgammas=np.sum(gammas,axis=1)\n",
    "    new_B=np.zeros([M,N])\n",
    "    for i in range(M) :\n",
    "        mask=np.array([o==i for o in obs[:-1] ])*1.0\n",
    "        new_B[i,:]=(np.sum(gammas*mask, axis=1)/sumgammas)\n",
    "\n",
    "    #Compute new A\n",
    "    sumlambd=np.sum(lambdas,axis=2)\n",
    "    new_A=sumlambd/sumgammas\n",
    "\n",
    "    #Compute new init\n",
    "    new_init=gammas[:,0]\n",
    "\n",
    "    #Compute log likehood\n",
    "    log_lik=-1*np.sum(np.log(np.array(cs)))\n",
    "\n",
    "    return new_A,new_B,new_init,log_lik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_init_prob_cols(n_rows,n_cols) :\n",
    "    answer=np.random.randn(n_cols*n_rows).reshape((n_rows,n_cols))\n",
    "    answer=np.exp(answer)\n",
    "    answer/=np.sum(answer,axis=0)[None,:]\n",
    "    return answer\n",
    "\n",
    "def train_HMM_on_seq_of_api_calls(line_as_number,n_hidden, n_obs):\n",
    "\n",
    "    \n",
    "    est_A=random_init_prob_cols(n_hidden,n_hidden)\n",
    "    est_B=random_init_prob_cols(n_obs,n_hidden)\n",
    "    est_init=np.ones(n_hidden)/n_hidden\n",
    "\n",
    "    for _ in range(15) :\n",
    "        est_A,est_B,est_init,log_lik=Baum_Welch_Norm_step(est_A,est_B,est_init,line_as_number)\n",
    "        est_B = np.maximum(est_B,.000001)\n",
    "        est_B /= (est_B.sum(axis=0)[None,:])\n",
    "        #print(\"  ----->\",_, \" : \" ,log_lik)\n",
    "    \n",
    "    return est_A, est_B, est_init\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_lik(a,b,init,obs):\n",
    "    N=a.shape[0]\n",
    "    M=b.shape[0]\n",
    "    T=len(obs)\n",
    "    cs=[]\n",
    "\n",
    "    # compute the alphas\n",
    "    alphas=np.zeros([a.shape[0],len(obs)])\n",
    "    alpha=(b[obs[0],:].ravel())*(init.ravel())\n",
    "    #print(\"alpha : \",alpha)\n",
    "    c=np.sum(alpha)\n",
    "    #print(\"c = \",c)\n",
    "    cs.append(1/c)\n",
    "    alpha/=c\n",
    "    alphas[:,0]=alpha\n",
    "    #print(\"alphas : \",alphas)\n",
    "    for i in range(1,len(obs)) :\n",
    "        alpha= b[obs[i],:]*np.matmul(a,alpha)\n",
    "        #print(i,\"alpha =\", alpha)\n",
    "        c=np.sum(alpha)\n",
    "        #print(i,\"c =\", c)\n",
    "        cs.append(1/c)\n",
    "        alpha/=c\n",
    "        alphas[:,i]=alpha\n",
    "\n",
    "    log_lik=-1*np.sum(np.log(np.array(cs)))\n",
    "    return log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hmm_f_for_row(row, n_hidden, n_obs):\n",
    "    a, b , init = train_HMM_on_seq_of_api_calls(row, n_hidden, n_obs)\n",
    "    init=np.ones(n_hidden)/n_hidden\n",
    "    def log_lik_hmm(other_row):\n",
    "        return log_lik(a,b,init,other_row)\n",
    "    return log_lik_hmm\n",
    "\n",
    "f =get_hmm_f_for_row(x[10],2,l )\n",
    "g =get_hmm_f_for_row(x[50],2,l )\n",
    "h =get_hmm_f_for_row(x[99],2,l )\n",
    "\n",
    "\"\"\" for i in range(1,l) : \n",
    "    f = get_hmm_f_for_row(x[i],2,l)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib\n",
    "L= [f(x[i]) for i in range(l)]\n",
    "M= [g(x[i]) for i in range(l)]\n",
    "N = [h(x[i]) for i in range(l)]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection= '3d')\n",
    "\n",
    "ax.scatter(L,M,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_step(D,indicies,l):\n",
    "    #d is dataset \n",
    "    #indicies  IS LISE OF INDICIES\n",
    "\n",
    "    fs = [get_hmm_f_for_row(D[i], 2, l) for i in indicies]\n",
    "    cloud=np.array([[fs[i](x) for i in range(len(indicies))] for x in D])\n",
    "    from sklearn.cluster import KMeans\n",
    "    k_means_model= KMeans(n_clusters=len(indicies), random_state=0, n_init='auto')\n",
    "    k_means_model.fit(cloud)\n",
    "    cs = k_means_model.cluster_centers_\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn_model.fit(cloud, range(cloud.shape[0]))\n",
    "    cs_closet = knn_model.predict(cs)\n",
    "\n",
    "    return cs_closet,k_means_model.inertia_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib\n",
    "new_x = x.copy()\n",
    "np.random.shuffle(new_x)\n",
    "new_x = new_x[:1000]\n",
    "indices = [0,1,2]\n",
    "inertias = []\n",
    "mix_step(new_x, indices,l)\n",
    "for i in range (10):\n",
    "    for j in range(10):\n",
    "        indices, inertia= mix_step(new_x, indices,l,)\n",
    "        inertias.append(inertia)\n",
    "        print(indices)\n",
    "\n",
    "plt.hist(inertias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
