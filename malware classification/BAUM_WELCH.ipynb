{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import matrix_power\n",
    "import random as rand \n",
    "\n",
    "\n",
    "def my_print(x):\n",
    "    m=0\n",
    "    for u in x.ravel() : \n",
    "        m=max(m,len((\"%.5f\" %u).rstrip(\"0\").rstrip(\".\").lstrip(\"0\")))\n",
    "    def form(u) :\n",
    "        return \" \"*(m-len((\"%.5f\" %u).rstrip(\"0\").rstrip(\".\").lstrip(\"0\")))+((\"%.5f\" %u).rstrip(\"0\").rstrip(\".\").lstrip(\"0\"))\n",
    "    np.set_printoptions(linewidth=130,formatter={\"float\" : lambda u:form(u)})\n",
    "    print(x)\n",
    "    np.set_printoptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><h1 style=\"border:solid;height:45px;padding-top:5px;border-radius:10px;width:400px;color:#AAAAFF;font-size:30px\">Markov Models</h1></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Markov model is specified by a square $N\\times N$ matrix $A$, all of whose entries are non-negative, and all of whose columns sum to $1$.\n",
    "\n",
    "The matrix $A$ is seen as a transition matrix between a set of states $\\{0,\\dots, N-1\\}$ where the entry at the intersection of the $i$-th row and the $j$-th column is \n",
    "$$a_{i,j}=P(\\ S_{n+1}=i \\ \\vert\\ S_{n} =j\\ )$$\n",
    "\n",
    "Then the matrix $P=A^k$ has for entries \n",
    "$$p_{i,j}=P(\\ S_{n+k}=i \\ \\vert\\ S_{n} =j\\ ) $$\n",
    "\n",
    "Let us first write a function that furnishes a sequence of observations of the states that follows the laws above :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MM_to_observations(A,init,size):\n",
    "    # A is the transition matrix ( size = N x N )\n",
    "    # init is the initial state ( integer between 0 and N-1 )\n",
    "    # size is the size of the sample (integer >0)\n",
    "\n",
    "    answer=[init]\n",
    "    N=A.shape[0]\n",
    "    X=list(range(N))\n",
    "    for i in range(size) :\n",
    "        distr=A[:,answer[i]]\n",
    "        answer.append(rand.choices(X,weights=distr)[0])\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our transition matrix is\n",
      "[[.3 .1 .3]\n",
      " [.2 .3 .2]\n",
      " [.5 .6 .5]]\n",
      "\n",
      "Here is a sample of 15 observations starting at the state 0 :\n",
      "[0, 2, 2, 2, 0, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1]\n",
      "\n",
      "If we take a longer sequence, say of 200000 states, we can make the following statistics :\n",
      "   -> proportion of 0's : 0.25495372523137383\n",
      "   -> proportion of 1's : 0.22158889205553972\n",
      "   -> proportion of 2's : 0.5234573827130864\n",
      "\n",
      "These proportions are to be compared to the value of A^k for k large (here k=100) :\n",
      "[[.25556 .25556 .25556]\n",
      " [.22222 .22222 .22222]\n",
      " [.52222 .52222 .52222]]\n"
     ]
    }
   ],
   "source": [
    "def test_MM_to_observations():\n",
    "    A=np.array([[.3,.1,.3],[.2,.3,.2],[.5,.6,.5]])\n",
    "    print(\"Our transition matrix is\")\n",
    "    my_print(A)\n",
    "    print(\"\\nHere is a sample of 15 observations starting at the state 0 :\")\n",
    "    print (MM_to_observations(A,0,15))\n",
    "    print(\"\\nIf we take a longer sequence, say of 200000 states, we can make the following statistics :\")\n",
    "    t=MM_to_observations(A,1,200000)\n",
    "    proportions=[]\n",
    "    for i in range(3) :\n",
    "        proportions.append(sum([1 for x in t if x==i])/len(t))\n",
    "        print (\"   -> proportion of {}'s : {}\".format(i,proportions[i]))\n",
    "    print(\"\\nThese proportions are to be compared to the value of A^k for k large (here k=100) :\")\n",
    "    my_print(matrix_power(A,100))\n",
    "\n",
    "test_MM_to_observations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us go in the other direction : we take a (long enough) sequence of observed states, postulated to have been obtain as a sample of a Markov model, as above. What is the matrix $A$ of this Markov Model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def observations_to_MM(N,obs):\n",
    "    #obs is a sequence of integers in the range 0...N-1\n",
    "    \n",
    "    answer=np.zeros([N,N])\n",
    "    for i in range(len(obs)-1) :\n",
    "        answer[obs[i+1],obs[i]]+=1\n",
    "    for i in range(N):\n",
    "        answer[:,i]/=np.sum(answer[:,i])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We compute a sample of 20000 observations from a MM with transition matrix \n",
      "[[.3 .1 .3]\n",
      " [.2 .3 .2]\n",
      " [.5 .6 .5]]\n",
      "\n",
      "Then we estimate the transition matrix from this sample :\n",
      "[[.31025 .09243 .30075]\n",
      " [ .2056 .30463  .1935]\n",
      " [.48415 .60294 .50575]]\n",
      "\n",
      "Quite close !!!\n"
     ]
    }
   ],
   "source": [
    "def test_observations_to_MM():\n",
    "    a=np.array([[.3,.1,.3],[.2,.3,.2],[.5,.6,.5]])\n",
    "    t=MM_to_observations(a,1,20000)\n",
    "    new_a=observations_to_MM(3,t)\n",
    "    print(\"We compute a sample of 20000 observations from a MM with transition matrix \")\n",
    "    my_print(a)\n",
    "    print (\"\\nThen we estimate the transition matrix from this sample :\")\n",
    "    my_print(new_a)\n",
    "    print(\"\\nQuite close !!!\")\n",
    "\n",
    "test_observations_to_MM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><h1 style=\"border:solid;height:45px;padding-top:5px;border-radius:10px;width:400px;color:#AAAAFF;font-size:30px\">Hidden Markov Models</h1></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we assume there exists a Markov model  with transition matrix $A$ whose $N$ states are unobservable, and that this model emits obvervable signals ranging from $0$ to $M-1$ via an emission matrix $B$ of size $M\\times N$ (see the lesson).\n",
    "\n",
    "\n",
    "The hidden states are written $(S_0,S_1,\\dots ,S_n,...)$. The observed signals are written $(O_0,O_1,\\dots ,O_n,...)$.\n",
    "\n",
    "Then the entry at the intersection of the $i$-th row and the $j$-th column of $B$ is \n",
    "$$b_{i,j}=P(\\ O_n = i\\ \\vert\\ S_n=j)$$\n",
    "\n",
    "Note that if we write $C=B\\times A^k$ (which is an $M\\times N$ matrix again) then\n",
    "$$c_{i,j}=P(\\ O_{n+k} = i\\ \\vert\\ S_n=j)$$\n",
    "\n",
    "Let us first assume $A$ and $B$ are known, and make some experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMM_to_sample(A,B,init,size) :\n",
    "    # A is the transition matrix (NxN)\n",
    "    # B is the emission matrix (MxN)\n",
    "    # init is the starting state (an integer in [0 ... N-1])\n",
    "\n",
    "    hidden = MM_to_observations(A,init,size)\n",
    "    obs = []\n",
    "    M=B.shape[0]\n",
    "    X=list(range(M))\n",
    "    for i in range(size) :\n",
    "        distr=B[:,hidden[i]]\n",
    "        obs.append(rand.choices(X,weights=distr)[0])\n",
    "    return hidden , obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 hidden states with transition matrix\n",
      "[[.3 .1 .2]\n",
      " [.2 .3 .3]\n",
      " [.5 .6 .5]]\n",
      "\n",
      "2 observable states with emission matrix\n",
      "[[.1 .4 .9]\n",
      " [.9 .6 .1]]\n",
      "\n",
      "here is a sample\n",
      "  hidden :    0 -> 2 -> 0 -> 2 -> 2 -> 0 -> 0 -> 2 -> 0 -> 0 -> 0 -> 2 -> 2 -> 1 -> 2 \n",
      "              |    |    |    |    |    |    |    |    |    |    |    |    |    |    |    \n",
      "              v    v    v    v    v    v    v    v    v    v    v    v    v    v    v    \n",
      "observed :    1    0    1    0    1    1    1    1    1    1    1    0    0    0    0    \n"
     ]
    }
   ],
   "source": [
    "def test_HMM_to_sample(show=True) :\n",
    "    A=np.array([[.3,.1,.2],[.2,.3,.3],[.5,.6,.5]])\n",
    "    B=np.array([[.1,.4,.9],[.9,.6,.1]])\n",
    "    if show : print(\"3 hidden states with transition matrix\")\n",
    "    if show :my_print(A)\n",
    "    if show : print(\"\\n2 observable states with emission matrix\")\n",
    "    if show :my_print(B)\n",
    "    if show : print(\"\\nhere is a sample\")\n",
    "    hid,obs=HMM_to_sample(A,B,0,15)\n",
    "    top_row=    \"  hidden :    \"\n",
    "    middle_row1=\"              \"\n",
    "    middle_row2=\"              \"\n",
    "    bottom_row= \"observed :    \"\n",
    "    for i in range(15) :\n",
    "        top_row+=    \"{} -> \".format(hid[i])\n",
    "        middle_row1+=\"|    \"\n",
    "        middle_row2+=\"v    \"\n",
    "        bottom_row+= \"{}    \".format(obs[i])\n",
    "    to_be_printed=top_row[:-3]+\"\\n\"+middle_row1+\"\\n\"+middle_row2+\"\\n\"+bottom_row\n",
    "    if show : print(to_be_printed)\n",
    "    return A,B,hid,obs,to_be_printed\n",
    "\n",
    "A,B,hid,obs,to_be_printed=test_HMM_to_sample()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><h1 style=\"border:solid;height:38px;padding-top:5px;border-radius:10px;width:400px;color:#DDAAFF;font-size:20px\">The derived Markov model </h1></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given such a hidden Markov model $\\mathcal H = (A,B,\\text{init})$ we can derive a simple Markov model corresponding to the observed states in two ways :\n",
    "- by taking a long sample of observations and using our function observations_to_MM \n",
    "- by directly computing $P(\\ [O_{s+1}=j]\\ \\vert\\  [O_{s}=i]\\ \\wedge\\ \\mathcal H )$.\n",
    "\n",
    "Let us first compute the transition probability (to avoid dependency to \\text{init} we will assume $s$ is large enough)\n",
    "$$\\begin{array}{ccl}\n",
    "&&P(\\ [O_{s+1}=j]\\ \\vert\\  [O_{s}=i]\\ \\wedge\\ \\mathcal H )\\\\\n",
    "&&\\\\\n",
    "&=&\\sum_{k} P(\\ [O_{s+1}=j]\\ \\wedge\\ [S_s=k]\\ \\vert\\ [O_{s}=i] \\wedge \\mathcal H )\\\\\n",
    "&&\\\\\n",
    "&=&\\sum_{k} P(\\ [O_{s+1}=j] \\ \\vert\\ [S_s=k]\\ \\wedge\\ [O_{s}=i] \\wedge \\mathcal H )\\times P(\\ [S_{s}=k] \\ \\vert\\  [O_{s}=i] \\wedge \\mathcal H )\\\\\n",
    "&&\\\\\n",
    "&=&\\sum_{k} P(\\ [O_{s+1}=j] \\ \\vert\\ [S_s=k]\\  \\wedge \\mathcal H )\\times P(\\ [O_{s}=i] \\ \\vert\\ [S_{s}=k] \\wedge \\mathcal H )\\frac{P([S_{s}=k]\\vert \\mathcal H)}{P([O_{s}=i]\\vert \\mathcal H)}\\\\\n",
    "&&\\\\\n",
    "&=&\\frac 1{P([O_{s}=i]\\vert \\mathcal H)}\\sum_k c_{j,k}b_{i,k}P([S_{s}=k]\\vert \\mathcal H)\n",
    "\\end{array} $$\n",
    "Now we just have to compute the values $P([S_{s}=k]\\vert \\mathcal H)$ but as we have seen above, these are contained in $A^{\\infty}$, and the values $P([O_{s}=j]\\vert \\mathcal H)$ but these are containes in $B*A^\\infty$.\n",
    "\n",
    "Let's compare the result of these two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMM_to_MM(A,B) :\n",
    "    A_infinity=matrix_power(A,100)\n",
    "    C=np.matmul(B,A)\n",
    "    M=B.shape[0]\n",
    "    N=B.shape[1]\n",
    "    D=np.transpose(np.array([A_infinity[:,0] for _ in range(M)]) * B)\n",
    "    E=np.matmul(C,D)\n",
    "    F=np.matmul(B,A_infinity)[:,0]\n",
    "    E=E/np.array([F for _ in range(M)])\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 hidden states with transition matrix\n",
      "[[.3 .1 .2]\n",
      " [.2 .3 .3]\n",
      " [.5 .6 .5]]\n",
      "\n",
      "2 observable states with emission matrix\n",
      "[[.1 .4 .9]\n",
      " [.9 .6 .1]]\n",
      "\n",
      "Here are the transition probabilities between the observed states (100000 observed states):\n",
      "\n",
      " -> via observations_to_MM :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60418146 0.60764083]\n",
      " [0.39581854 0.39235917]]\n",
      "\n",
      " -> via HMM_to_HM :\n",
      "[[0.60387037 0.61117143]\n",
      " [0.39612963 0.38882857]]\n"
     ]
    }
   ],
   "source": [
    "def test_HMM_to_MM() :\n",
    "    A=np.array([[.3,.1,.2],[.2,.3,.3],[.5,.6,.5]])\n",
    "    B=np.array([[.1,.4,.9],[.9,.6,.1]])\n",
    "    print(\"3 hidden states with transition matrix\")\n",
    "    my_print(A)\n",
    "    print(\"\\n2 observable states with emission matrix\")\n",
    "    my_print(B)\n",
    "    print(\"\\nHere are the transition probabilities between the observed states (100000 observed states):\")\n",
    "    print(\"\\n -> via observations_to_MM :\")\n",
    "    print(observations_to_MM(2,HMM_to_sample(A,B,0,100000)[1]))\n",
    "    print(\"\\n -> via HMM_to_HM :\")\n",
    "    print(HMM_to_MM(A,B))\n",
    "\n",
    "test_HMM_to_MM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the two methods give the same results. The resulting Markov model is called the **derived Markov model**. As we will see (and as a short observation makes seem natural), the knowledge of the hidden Markov Model (even when the hidden states are left unobserved) allow a better prediction of the observation to come than the derived MM.\n",
    "\n",
    "**This means that when a MM is derived from a HMM, it may be worthwhile to identify this HMM. This is our goal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><h1 style=\"border:solid;height:38px;padding-top:5px;border-radius:10px;width:400px;color:#DDAAFF;font-size:20px\">Computing P(Observations) </h1></center></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume we are given a HMM : $A$ and $B$ are known. We also have an idea of the initial distribution on the hidden states, i.e. we have a vector $$\\text{hid}_0=\\begin{bmatrix} P(S_0=0)\\\\ \\vdots \\\\ P(S_0=N-1)\\end{bmatrix}$$\n",
    "\n",
    "Let $\\mathcal{H}=(A,B,\\text{hid}_0)$ be our knowledge.\n",
    "\n",
    "We want to compute \n",
    "\n",
    "$$P(\\ \\text{obs}\\ \\vert\\ \\mathcal H\\ )= P(\\ [O_0=k_0]\\ \\wedge\\ [O_1=k_1]  \\ \\wedge\\  \\cdots \\ \\wedge\\   [O_n=k_n] \\ \\vert\\ \\mathcal{H}\\ )$$\n",
    "\n",
    "We do so by induction, introducing \n",
    "$$\\alpha_n (i)= P(\\ [O_0=k_0] \\ \\wedge\\   \\cdots \\ \\wedge\\   [O_n=k_n] \\ \\wedge\\   [S_{n}=i]\\ \\vert\\ \\mathcal{H}\\ )$$\n",
    "and \n",
    "$$\\alpha_n = \\begin{bmatrix} \\alpha_n(0)& \\cdots & \\alpha_n(N-1)\\end{bmatrix}$$\n",
    "\n",
    "Then \n",
    "$$\\alpha_0(i) = P(\\ [O_0=k_0] \\ \\wedge\\   [S_{0}=i]\\ \\vert\\ \\mathcal{H}\\ ) = P(\\ [O_0=k_0]\\  \\vert\\ [S_{0}=i]\\ \\wedge\\   \\mathcal{H})\\times P([S_{0}=i]\\ \\vert\\ \\mathcal{H}\\ ) = b_{k_0,i}\\times \\text{hid}_0(i) $$\n",
    "Which we can write in matrix notation as\n",
    "$$\\alpha_0=e_{k_0}\\cdot B\\cdot\\text{hid}_0$$\n",
    "\n",
    "Now $$\\begin{array}{ccl}\n",
    "\\alpha_1(i)&=& P(O_0=k_0 \\ \\wedge\\   O_1=k_1\\ \\wedge\\  S_{1}=i\\ \\vert\\ \\mathcal{H})\\\\\n",
    " &&\\\\\n",
    " &=& P([O_0=k_0] \\ \\wedge\\   [[S_0=0\\ \\vee\\ \\dots\\ \\vee\\ S_0=N-1]]\\ \\wedge\\ [O_1=k_1]\\ \\wedge\\  [S_{1}=i]\\ \\vert\\ \\mathcal{H})\\\\\n",
    " &&\\\\\n",
    " &=&\\sum_{j=0}^{N-1}P([O_0=k_0] \\ \\wedge\\   [S_0=j]\\ \\wedge\\ [O_1=k_1]\\ \\wedge\\  [S_{1}=i]\\ \\vert\\ \\mathcal{H})\n",
    " \\end{array}$$\n",
    " and\n",
    " $$\\begin{array}{ccl}\n",
    " &&P([O_0=k_0] \\ \\wedge\\   [S_0=j]\\ \\wedge\\ [O_1=k_1]\\ \\wedge\\  [S_{1}=i]\\ \\vert\\ \\mathcal{H})\\\\\n",
    " &=&\\\\\n",
    " &=&P([O_1=k_1]\\ \\vert\\ [O_0=k_0] \\ \\wedge\\   [S_0=j]\\ \\wedge\\  [S_{1}=i] \\ \\wedge\\ \\mathcal{H})\\times P([O_0=k_0] \\ \\wedge\\   [S_0=j]\\ \\wedge\\  [S_{1}=i])\\\\\n",
    " &=&\\\\\n",
    " &=&P([O_1=k_1]\\ \\vert\\  [S_{1}=i] \\ \\wedge\\ \\mathcal{H})\\times P([O_0=k_0] \\ \\wedge\\   [S_0=j]\\ \\wedge\\  [S_{1}=i]\\ \\vert\\ \\mathcal{H})\\\\\n",
    " &&\\\\\n",
    "& =& b_{k_1,i} P([S_{1}=i]\\ \\vert\\ [O_0=k_0] \\ \\wedge\\   [S_0=j]\\ \\wedge\\ \\mathcal{H})\\\\\n",
    "&&\\\\\n",
    "&=& b_{k_1,i} a_{i,j}P([O_0=k_0] \\ \\wedge\\   [S_0=j]\\ \\wedge\\ \\mathcal{H})\\\\\n",
    "&&\\\\\n",
    "& =& b_{k_1,i} a_{i,j}\\alpha_0(j) \n",
    "\\end{array}$$\n",
    "so in numpy notation, we get the following formula :\n",
    "$$\\alpha_1 = B[k_1,:]*\\text{matmul}(A,\\alpha_0)$$\n",
    "and similarly\n",
    "$$\\alpha_{s+1} = B[k_{s+1},:]*\\text{matmul}(A,\\alpha_s)$$\n",
    "\n",
    "The implementation of this recursion is often called the **forward algorithm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_pass(a,b,init,obs) :\n",
    "    # computes alpha_k = P( Obs[:k] and s_k | (a,b,init) )\n",
    "    alphas=np.zeros([a.shape[0],len(obs)])\n",
    "    alpha=(b[obs[0],:].ravel())*(init.ravel())\n",
    "    alphas[:,0]=alpha\n",
    "    for i in range(1,len(obs)) :\n",
    "        alpha= b[obs[i],:]*np.matmul(a,alpha) \n",
    "        alphas[:,i]=alpha\n",
    "    return alphas\n",
    "\n",
    "def forward(a,b,init,obs) :\n",
    "    return np.sum(alpha_pass(a,b,init,obs), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " We continue with the previous example :\n",
      "  hidden :    0 -> 2 -> 1 -> 2 -> 1 -> 2 -> 2 -> 0 -> 2 -> 2 -> 1 -> 1 -> 1 -> 2 -> 2 \n",
      "              |    |    |    |    |    |    |    |    |    |    |    |    |    |    |    \n",
      "              v    v    v    v    v    v    v    v    v    v    v    v    v    v    v    \n",
      "observed :    1    0    1    0    1    0    0    1    0    0    1    1    1    0    0    \n",
      "\n",
      "Lets use alpha_pass on this sample of observations (so the hidden states are assumed to be unobserved) with a uniform initial distribution on the hidden states. We get :\n",
      "\n",
      "[[  .297 .01157 .05382 .00251 .01306 .00061 .00035 .00189 .00009 .00005 .00028 .00012 .00005              ]\n",
      " [  .198  .0516 .05673 .01309 .01387 .00319 .00225 .00204 .00047 .00033  .0003  .0001 .00004 .00001 .00001]\n",
      " [  .034 .25587 .01647 .06227 .00402 .01518 .00883 .00059 .00222 .00129 .00009 .00004 .00001 .00005 .00003]]\n",
      "\n",
      "If we sum up the columns we get the (result of the forward function which is the list of) probabilities of observing the sequence up to the corresponding rank :\n",
      "\n",
      "[  .529 .31904 .12703 .07787 .03095 .01898 .01144 .00452 .00277 .00167 .00066 .00026  .0001 .00006 .00004]\n"
     ]
    }
   ],
   "source": [
    "def test_alpha_pass():\n",
    "    A,B,hid,obs,to_be_printed1=test_HMM_to_sample(show=False)\n",
    "    print(\"\\n We continue with the previous example :\")\n",
    "    print(to_be_printed1)\n",
    "    print(\"\"\"\\nLets use alpha_pass on this sample of observations (so the hidden states are assumed to be unobserved) with a uniform initial distribution on the hidden states. We get :\\n\"\"\")\n",
    "    init=np.array([.33,.33,.34])\n",
    "    alphas=alpha_pass(A,B,init,obs)\n",
    "    my_print(alphas)\n",
    "    print(\"\\nIf we sum up the columns we get the (result of the forward function which is the list of) probabilities of observing the sequence up to the corresponding rank :\\n\")\n",
    "    my_print(np.sum(alphas,axis=0))\n",
    "\n",
    "test_alpha_pass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the sequence above decreases exponentially fast, which will be a concern when we will use longer samples, but for now, let's forget about it.\n",
    "\n",
    "We can now compare the results of the forward function with the 3 possible initial states :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    .9   .504 .20169 .12353 .04911 .03011 .01814 .01097 .00664 .00401 .00159 .00097 .00059 .00035 .00021]\n",
      " [    .6   .402 .15924 .09772 .03884 .02382 .01435 .00868 .00525 .00317 .00125 .00077 .00046 .00028 .00017]\n",
      " [    .1   .059 .02329 .01429 .00568 .00348  .0021 .00127 .00077 .00046 .00018 .00011 .00007 .00004 .00002]]\n"
     ]
    }
   ],
   "source": [
    "def forward_from_possible_inits(A,B,obs) :\n",
    "    N=A.shape[0]\n",
    "    inits=np.diag(np.ones(N))\n",
    "    return np.array([forward(A,B,inits[:,i],obs) for i in range(N)])\n",
    "\n",
    "def test_forward_from_possible_inits() :\n",
    "    A,B,hid,obs,to_be_printed1=test_HMM_to_sample(show=False)\n",
    "    my_print(forward_from_possible_inits(A,B,obs))\n",
    "\n",
    "test_forward_from_possible_inits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this example it is clear that the most probable initial state was $S_0=0$ (and indeed, it was our starting hidden value). Can we also guess what is, say, the most probable fifth state ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><h1 style=\"border:solid;height:38px;padding-top:5px;border-radius:10px;width:400px;color:#DDAAFF;font-size:20px\">Uncovering the hidden states </h1></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute $$\\gamma_k(i)=P(S_k=i \\ \\vert\\ \\text{obs}\\ \\wedge\\ \\mathcal H)$$\n",
    "\n",
    "We have : $$P(S_k=k \\ \\vert\\ \\text{obs}\\ \\wedge\\ \\mathcal H)=\\frac{P(S_k=k\\ \\wedge\\ \\text{obs}\\ \\vert\\ \\mathcal H)}{P(\\text{obs}\\ \\vert\\ \\mathcal H)} $$\n",
    "and \n",
    "$$P(S_k=k\\ \\wedge\\ \\text{obs}\\ \\vert\\ \\mathcal H)=P(\\text{obs}_0 \\wedge \\dots \\wedge \\text{obs}_k \\wedge [S_k=i] \\wedge \\text{obs}_{k+1}\\wedge\\dots\\wedge\\text{obs}_{n}\\vert \\mathcal H) =P(\\text{obs}_0 \\wedge \\dots \\wedge \\text{obs}_k \\wedge [S_k=i] \\vert \\mathcal H)\\times P(\\text{obs}_{k+1} \\wedge \\dots \\wedge \\text{obs}_n\\  \\vert\\ [S_k=i] \\wedge \\mathcal H) $$\n",
    "(note that it is important here to know that once you know $S_k$, you don't get more information about $O_{k+1}$ if you assume $O_k$, $O_{k-1}$, ... and $S_{k-1}$, $S_{k-2}$ ... are known.)\n",
    "\n",
    "So writing \n",
    "$$\\beta_k(i)=P(\\text{obs}_{k+1} \\wedge \\dots \\wedge \\text{obs}_n\\  \\vert\\ [S_k=i] \\wedge \\mathcal H)$$\n",
    "we get\n",
    "$$P(S_k=k \\ \\vert\\ \\text{obs}\\ \\wedge\\ \\mathcal H)=\\frac{\\alpha_k(i)\\beta_k(i)}{P(\\text{obs}\\ \\vert\\ \\mathcal H)}$$\n",
    "Since the $\\alpha$'s are computed (via the alpha_pass function ), and so is $P(\\text{obs}\\ \\vert\\ \\mathcal H)$ (via the forward function) we are left with computing the $\\beta$'s\n",
    "\n",
    "Once again we will use an induction, but this time starting from the end : indeed, we know \n",
    "$$\\beta_n(i)=P(O_n=k_n\\vert s_{n-1}=i)=(BA)_{k_n,i}$$\n",
    "and just as we did for the alphas, we can derive the induction formula\n",
    "$$\\beta_{s}(i)=\\sum_j b_{k_{s+1},j}a_{j,i}\\beta_{s+1}(j)$$\n",
    "which we can rewrite in numpy notation as\n",
    "$$\\beta_s =\\text{matmul}(\\ B[k_{s+1},j]*\\beta_{s+1}\\ ,\\ A\\ )$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_pass(a,b,obs) :\n",
    "    \n",
    "    T=len(obs)\n",
    "    betas=np.zeros([a.shape[0],T])\n",
    "    beta=np.matmul(b,a)[obs[T-1],:]\n",
    "    betas[:,T-2]=beta\n",
    "    for i in range(1,T-1) :\n",
    "        beta=np.matmul(b[obs[T-i-1],:]*beta,a)\n",
    "        betas[:,T-i-2]=beta\n",
    "    betas[:,T-1]=np.ones(a.shape[0])   #Coherent with the formulas, allows to have an array of the same size as the alphas\n",
    "    return betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gamma_pass(a,b,init,obs):\n",
    "    alphas=alpha_pass(a,b,init,obs) \n",
    "    betas=beta_pass(a,b,obs)\n",
    "    tot=np.sum(alphas[:,-1])\n",
    "    gammas=alphas*betas/tot\n",
    "    return gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hidden :    0 -> 2 -> 2 -> 2 -> 1 -> 1 -> 1 -> 2 -> 2 -> 2 -> 1 -> 1 -> 1 -> 2 -> 0 \n",
      "              |    |    |    |    |    |    |    |    |    |    |    |    |    |    |    \n",
      "              v    v    v    v    v    v    v    v    v    v    v    v    v    v    v    \n",
      "observed :    1    0    0    0    0    1    1    0    0    0    0    1    0    0    1    \n",
      "[[.00015 .00024  .0004 .00067 .00137 .00332 .00709 .01173 .01939 .03268 .06208 .13276  .2241    .44      1]\n",
      " [.00017 .00029 .00048 .00079 .00096 .00263 .00855 .01413 .02335 .03878 .04919 .15985  .2654    .33      1]\n",
      " [.00015 .00026 .00042  .0007 .00123 .00319 .00754 .01247 .02062 .03402 .05973 .14113  .2329    .41      1]]\n",
      "\n",
      "Choosing an initial distribution of [.33, .33, .34] our gammas are\n",
      "[[ .5195 .03346 .02861  .0285 .03517 .46331 .41982 .03118 .02846 .02838 .03261 .37957 .03017 .03444 .41767]\n",
      " [.41727  .1798 .21781 .21796 .16009 .39635 .44274 .18566 .21781 .21807 .16736 .49339 .18767 .16455 .45081]\n",
      " [.06323 .78674 .75359 .75354 .80474 .14034 .13744 .78317 .75373 .75355 .80003 .12704 .78216 .80101 .13152]]\n",
      "\n",
      "Summing up the columns we obtain\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "which is reassuring : up to now, there's no evidence our code is flawed !\n"
     ]
    }
   ],
   "source": [
    "def test_gammas() :\n",
    "    A,B,hid,obs,to_be_printed1=test_HMM_to_sample(show=False)\n",
    "    print(to_be_printed1)\n",
    "    my_print(beta_pass(A,B,obs))\n",
    "\n",
    "    print(\"\\nChoosing an initial distribution of [.33, .33, .34] our gammas are\")\n",
    "    init=np.array([.33,.33,.34])\n",
    "    gammas=gamma_pass(A,B,init,obs)\n",
    "    my_print(gammas)\n",
    "    print(\"\\nSumming up the columns we obtain\")\n",
    "    my_print(np.sum(gammas,axis=0))\n",
    "    print(\"which is reassuring : up to now, there's no evidence our code is flawed !\")\n",
    "\n",
    "test_gammas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can \"uncover\" the hidden states :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_probable(A,B,init,obs) :\n",
    "    gammas=gamma_pass(A,B,init,obs)\n",
    "    return np.argmax( gammas, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hidden :    0 -> 2 -> 2 -> 0 -> 0 -> 1 -> 2 -> 2 -> 2 -> 1 -> 2 -> 2 -> 0 -> 2 -> 2 \n",
      "              |    |    |    |    |    |    |    |    |    |    |    |    |    |    |    \n",
      "              v    v    v    v    v    v    v    v    v    v    v    v    v    v    v    \n",
      "observed :    1    0    0    1    1    0    0    0    0    1    0    0    1    0    0    \n",
      "\n",
      "In this situation, with an initial distribution of [.33, .33, .34], the most probable hidden states are :\n",
      "[0 2 2 0 1 2 2 2 2 1 2 2 1 2 2]\n",
      "\n",
      "Let us estimate the average of good answers on 100 trys :\n",
      "average score :  0.626875\n"
     ]
    }
   ],
   "source": [
    "def test_most_probable():\n",
    "    A,B,hid,obs,to_be_printed1=test_HMM_to_sample(show=False)\n",
    "    print(to_be_printed1)\n",
    "    print(\"\\nIn this situation, with an initial distribution of [.33, .33, .34], the most probable hidden states are :\")\n",
    "    print(most_probable(A,B,np.array([.33,.33,.34]),obs))\n",
    "    print(\"\\nLet us estimate the average of good answers on 100 trys :\")\n",
    "    good=0\n",
    "    N=100\n",
    "    for i in range(N) :\n",
    "        A,B,hid,obs,to_be_printed1=test_HMM_to_sample(show=False)\n",
    "        most=most_probable(A,B,np.array([.33,.33,.34]),obs)\n",
    "        good+=sum([1 for i in range(len(most)) if hid[i]==most[i]])\n",
    "    print(\"average score : \", good/(len(hid)*N))\n",
    "test_most_probable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><h1 style=\"border:solid;height:38px;padding-top:5px;border-radius:10px;width:400px;color:#DDAAFF;font-size:20px\">Estimating  B from obs </h1></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to check our implementations so far are flawless comes from the following remark :\n",
    "\n",
    "As the size of the sample goes large, the ratio\n",
    "$$\\frac{\\displaystyle\\sum_{s\\ :\\ O_s=i} \\gamma_s(j)}{\\displaystyle\\sum_{s} \\gamma_s(j)}$$\n",
    "should converge to $b_{i,j}$.\n",
    "\n",
    "Also, this will be useful later : if we start with a given set of observations and a random HMM $\\mathcal H_0=(A_0,B_0,\\text{init}_0)$, then $\\mathcal H_1=(A_0,B_1,\\text{init}_0)$ will be a better model (where $B_1$ is the evaluated $B$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 hidden states with transition matrix\n",
      "[[.3 .1 .2]\n",
      " [.2 .3 .3]\n",
      " [.5 .6 .5]]\n",
      "\n",
      "2 observable states with emission matrix\n",
      "[[.1 .4 .9]\n",
      " [.9 .6 .1]]\n",
      "\n",
      "Estimated B from 1000 observations :\n",
      "[[0.08934776 0.36885024 0.88813168]\n",
      " [0.91065224 0.63114976 0.11186832]]\n"
     ]
    }
   ],
   "source": [
    "def gammas_and_obs_to_B(N,M,gammas,obs):\n",
    "    sumgammas=np.sum(gammas,axis=1)\n",
    "    answer=np.zeros([M,N])\n",
    "    for i in range(M) :\n",
    "        mask=np.array([o==i for o in obs ])*1.0\n",
    "        answer[i,:]=(np.sum(gammas*mask, axis=1)/sumgammas)\n",
    "    return answer\n",
    "\n",
    "def test_gammas_and_obs_to_B():\n",
    "    A=np.array([[.3,.1,.2],[.2,.3,.3],[.5,.6,.5]])\n",
    "    B=np.array([[.1,.4,.9],[.9,.6,.1]])\n",
    "    print(\"3 hidden states with transition matrix\")\n",
    "    my_print(A)\n",
    "    print(\"\\n2 observable states with emission matrix\")\n",
    "    my_print(B)\n",
    "    hid,obs=HMM_to_sample(A,B,0,1000)\n",
    "    gammas=gamma_pass(A,B,np.array([1,0,0]),obs)\n",
    "    print(\"\\nEstimated B from 1000 observations :\")\n",
    "    print(gammas_and_obs_to_B(3,2,gammas,obs))\n",
    "\n",
    "test_gammas_and_obs_to_B()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><h1 style=\"border:solid;height:38px;padding-top:5px;border-radius:10px;width:400px;color:#DDAAFF;font-size:20px\">Estimating A from obs </h1></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to do the same with $A$. Let us write $\\lambda_s(i,j)=P([S_s=j]\\ \\wedge \\ [S_{s+1}=i] \\vert \\text{obs} \\wedge \\mathcal H)$.\n",
    "\n",
    "Then just as in the function observations_to_MM we see that \n",
    "$$\\frac{\\sum_s \\lambda_s(i,j)}{\\sum_s \\gamma_s(i)}$$\n",
    "should converge to $a_{i,j}$ as the sample goes large.\n",
    "\n",
    "Now computations like the ones we did to find a formula for $\\alpha$ give :\n",
    "$$\\lambda_s(i,j)=\\frac{\\beta_{s+1}(i)\\times b_{O_{s+1},i}\\times a_{i,j}\\times \\alpha_s(j)}{P(\\ \\text{obs}\\ \\vert\\ \\mathcal H\\ )}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 hidden states with transition matrix\n",
      "[[.3 .1 .2]\n",
      " [.2 .3 .3]\n",
      " [.5 .6 .5]]\n",
      "\n",
      "2 observable states with emission matrix\n",
      "[[.1 .4 .9]\n",
      " [.9 .6 .1]]\n",
      "\n",
      " Computing the lambdas, and then suming the (square) slices gives\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      " Once again, everything looks all right !\n"
     ]
    }
   ],
   "source": [
    "def lambda_pass(A,B,init,obs) :\n",
    "    N=A.shape[0]\n",
    "    T=len(obs)\n",
    "    alphas=alpha_pass(A,B,init,obs)\n",
    "    betas=beta_pass(A,B,obs)\n",
    "    lambdas=np.zeros([N,N,T-1])\n",
    "    for s in range(T-1) :\n",
    "        lambdas[:,:,s]=np.transpose((betas[:,s+1]*B[obs[s+1],:])*np.transpose(A*alphas[:,s]))\n",
    "    probobs=np.sum(alphas[:,-1])\n",
    "    return lambdas/probobs\n",
    "\n",
    "def test_lambdas():\n",
    "    A=np.array([[.3,.1,.2],[.2,.3,.3],[.5,.6,.5]])\n",
    "    B=np.array([[.1,.4,.9],[.9,.6,.1]])\n",
    "    print(\"3 hidden states with transition matrix\")\n",
    "    my_print(A)\n",
    "    print(\"\\n2 observable states with emission matrix\")\n",
    "    my_print(B)\n",
    "    hid,obs=HMM_to_sample(A,B,0,30)\n",
    "    lambdas=lambda_pass(A,B,np.array([0,0,1]),obs)\n",
    "    print(\"\\n Computing the lambdas, and then suming the (square) slices gives\")\n",
    "    print(np.sum(np.sum(lambdas,axis=0),axis=0))\n",
    "    print(\"\\n Once again, everything looks all right !\")\n",
    "\n",
    "test_lambdas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's estimate $A$ from the lambdas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 hidden states with transition matrix\n",
      "[[.3 .1 .2]\n",
      " [.2 .3 .3]\n",
      " [.5 .6 .5]]\n",
      "\n",
      "2 observable states with emission matrix\n",
      "[[.1 .4 .9]\n",
      " [.9 .6 .1]]\n",
      "here is the estimated transition matrix A_est\n",
      "[[0.28644895 0.09465508 0.19535963]\n",
      " [0.19555206 0.29283796 0.301387  ]\n",
      " [0.517999   0.61250695 0.50325336]]\n"
     ]
    }
   ],
   "source": [
    "def lambdas_to_A(A,B,init,obs) :\n",
    "    lambdas=lambda_pass(A,B,init,obs)\n",
    "    gammas=gamma_pass(A,B,init,obs)[:,:-1]\n",
    "    sumlambd=np.sum(lambdas,axis=2)\n",
    "    sumgam=np.sum(gammas,1)\n",
    "    return sumlambd/sumgam, gammas\n",
    "\n",
    "def test_lambdas_to_A():\n",
    "    A=np.array([[.3,.1,.2],[.2,.3,.3],[.5,.6,.5]])\n",
    "    B=np.array([[.1,.4,.9],[.9,.6,.1]])\n",
    "    print(\"3 hidden states with transition matrix\")\n",
    "    my_print(A)\n",
    "    print(\"\\n2 observable states with emission matrix\")\n",
    "    my_print(B)\n",
    "    init=np.array([0,0,1])\n",
    "    hid,obs=HMM_to_sample(A,B,0,1000)\n",
    "    print(r\"here is the estimated transition matrix A_est\")\n",
    "    estA,gammas=lambdas_to_A(A,B,init,obs)\n",
    "    print(estA)\n",
    "\n",
    "test_lambdas_to_A()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><h1 style=\"border:solid;height:38px;padding-top:5px;border-radius:10px;width:400px;color:#DDAAFF;font-size:20px\">The Baum-Welch algorithm</h1></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have all the tools to implement the Baum-Welch algorithm.\n",
    "\n",
    "As we have seen, given a HMM $\\mathcal H=(A,B,init)$, we are able, given a large sample of observations, to estimate the matrices $A$ and $B$ and the initial state init.\n",
    "\n",
    "In other words, given a very very very large sample of observations, $\\mathcal H$ is a fixed point of the application\n",
    "$$\\mathcal H\\mapsto \\text{Estimation} (\\mathcal H\\ \\vert\\ obs\\wedge \\mathcal H)$$\n",
    "\n",
    "The idea of the Baum-Welch algorithm is that this fixed point should be attractrive (we won't prove this here) so that choosing a random initial HMM $\\mathcal H_0$ the sequence defined by\n",
    "$$\\mathcal H_{n+1}=\\text{Estimation} (\\mathcal H_n\\ \\vert\\ obs\\wedge \\mathcal H_n)$$\n",
    "should converge to $\\mathcal H$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 hidden states with transition matrix\n",
      "[[.7 .3]\n",
      " [.3 .7]]\n",
      "\n",
      "2 observable states with emission matrix\n",
      "[[.4 .9]\n",
      " [.6 .1]]\n",
      "\n",
      "Derived MM :\n",
      "[[.68846 .57857]\n",
      " [.31154 .42143]]\n",
      "starting with A,B, init :\n",
      "[[0.6 0.2]\n",
      " [0.4 0.8]] \n",
      "\n",
      " [[0.3 0.8]\n",
      " [0.7 0.2]] \n",
      "\n",
      " [0 1]\n",
      "after 100 Baum-Welch steps :\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated A,B, init:\n",
      "[[0.8451203  0.09869343]\n",
      " [0.1548797  0.90130657]] \n",
      "\n",
      " [[0.42389696 0.78460756]\n",
      " [0.57610304 0.21539244]] \n",
      "\n",
      " [0. 1.]\n",
      "\n",
      "Derived MM :\n",
      "[[.68005 .57932]\n",
      " [.31995 .42068]]\n",
      "\n",
      "after 1000 more Baum-Welch steps :\n",
      "\n",
      "Estimated A,B, init:\n",
      "[[0.8901438  0.05260891]\n",
      " [0.1098562  0.94739109]] \n",
      "\n",
      " [[0.41809826 0.75161399]\n",
      " [0.58190174 0.24838601]] \n",
      "\n",
      " [0. 1.]\n",
      "\n",
      "Derived MM :\n",
      "[[.67531 .58638]\n",
      " [.32469 .41362]]\n"
     ]
    }
   ],
   "source": [
    "def Baum_Welch(A,B,init,obs,n_iter) :\n",
    "    N=A.shape[0]\n",
    "    M=B.shape[0]\n",
    "    #A=(np.ones([N,N])+2*np.diag(np.ones(N)))/(N+2)\n",
    "    #B=np.ones([M,N])/M\n",
    "    #init=np.ones(N)/N\n",
    "    for _ in range(n_iter) :\n",
    "        A,gammas=lambdas_to_A(A,B,init,obs)\n",
    "        B=gammas_and_obs_to_B(N,M,gammas,obs[:-1])\n",
    "        init=gammas[:,0]\n",
    "        #print (A,\"\\n\\n\",B,\"\\n\\n\",init,\"\\n\\n\")\n",
    "    return A,B,init\n",
    "\n",
    "def test_Baum_Welch_1():\n",
    "    A=np.array([[.3,.1,.2],[.2,.3,.3],[.5,.6,.5]])\n",
    "    B=np.array([[.1,.4,.9],[.9,.6,.1]])\n",
    "    print(\"3 hidden states with transition matrix\")\n",
    "    my_print(A)\n",
    "    print(\"\\n2 observable states with emission matrix\")\n",
    "    my_print(B)\n",
    "    init=np.array([0,0,1])\n",
    "    hid,obs=HMM_to_sample(A,B,0,1000)\n",
    "    A=np.array([[.4,.1,.2],[.2,.3,.3],[.4,.6,.5]])\n",
    "    B=np.array([[.1,.4,.8],[.9,.6,.2]])\n",
    "    estA,estB,estinit=Baum_Welch(A,B,init,obs,1000)\n",
    "    print(estA,\"\\n\\n\",estB,\"\\n\\n\",estinit)\n",
    "\n",
    "def test_Baum_Welch_3():\n",
    "    A=np.array([[.7,.3],[.3,.7],])\n",
    "    B=np.array([[.4,.9,],[.6,.1]])\n",
    "    print(\"2 hidden states with transition matrix\")\n",
    "    my_print(A)\n",
    "    print(\"\\n2 observable states with emission matrix\")\n",
    "    my_print(B)\n",
    "    print(\"\\nDerived MM :\")\n",
    "    my_print(HMM_to_MM(A,B))\n",
    "    init=np.array([0,1])\n",
    "    hid,obs=HMM_to_sample(A,B,0,500)\n",
    "    A=np.array([[.6,.2],[.4,.8],])\n",
    "    B=np.array([[.3,.8],[.7,.2]])\n",
    "    print(\"starting with A,B, init :\")\n",
    "    print(A,\"\\n\\n\",B,\"\\n\\n\",init)\n",
    "    \n",
    "    print(\"after 100 Baum-Welch steps :\\n\")\n",
    "    estA,estB,estinit=Baum_Welch(A,B,init,obs,100)\n",
    "    \n",
    "    print(\"\\nEstimated A,B, init:\")\n",
    "    print(estA,\"\\n\\n\",estB,\"\\n\\n\",estinit)\n",
    "    print(\"\\nDerived MM :\")\n",
    "    my_print(HMM_to_MM(estA,estB))\n",
    "    \n",
    "    print(\"\\nafter 1000 more Baum-Welch steps :\")\n",
    "    estA,estB,estinit=Baum_Welch(estA,estB,estinit,obs,1000)\n",
    "    \n",
    "    print(\"\\nEstimated A,B, init:\")\n",
    "    print(estA,\"\\n\\n\",estB,\"\\n\\n\",estinit)\n",
    "    print(\"\\nDerived MM :\")\n",
    "    my_print(HMM_to_MM(estA,estB))\n",
    "    \n",
    "    \n",
    "\n",
    "test_Baum_Welch_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><center><h1 style=\"border:solid;height:38px;padding-top:5px;border-radius:10px;width:400px;color:#DDAAFF;font-size:20px\">Normalized Baum-Welch algorithm</h1></center></p>\n",
    "\n",
    "To be able to consider longer sequences of observations we modify slightly the computations inside the BW algorithm, by normalizing the alphas and the betas, which is finally provably transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Baum_Welch_Norm_step(a,b,init,obs) :\n",
    "    print (obs)\n",
    "    N=a.shape[0]\n",
    "    M=b.shape[0]\n",
    "    T=len(obs)\n",
    "    cs=[]\n",
    "\n",
    "    # compute the alphas\n",
    "    alphas=np.zeros([a.shape[0],len(obs)])\n",
    "    alpha=(b[obs[0],:].ravel())*(init.ravel())\n",
    "    c=np.sum(alpha)\n",
    "    cs.append(1/c)\n",
    "    alpha/=c\n",
    "    alphas[:,0]=alpha\n",
    "    for i in range(1,len(obs)) :\n",
    "        alpha= b[obs[i],:]*np.matmul(a,alpha) \n",
    "        c=np.sum(alpha)\n",
    "        cs.append(1/c)\n",
    "        alpha/=c\n",
    "        alphas[:,i]=alpha\n",
    "    \n",
    "\n",
    "    # Compute the betas\n",
    "    \n",
    "    betas=np.zeros([a.shape[0],T])\n",
    "    beta=np.ones(a.shape[0])*cs[T-1]\n",
    "    betas[:,T-1]=beta\n",
    "    for i in range(1,T-1) :\n",
    "        beta=np.matmul(b[obs[T-i],:]*beta,a)\n",
    "        beta*=cs[T-i-1]\n",
    "        betas[:,T-i-1]=beta\n",
    "\n",
    "    \n",
    "    #Compute the lambdas\n",
    "    lambdas=np.zeros([N,N,T-1])\n",
    "    for s in range(T-1) :\n",
    "        lambdas[:,:,s]=np.transpose((betas[:,s+1]*b[obs[s+1],:])*np.transpose(a*alphas[:,s]))\n",
    "\n",
    "\n",
    "    #Compute the gammas\n",
    "    gammas=np.sum(lambdas, axis=0)\n",
    "\n",
    "    #Compute new B \n",
    "    sumgammas=np.sum(gammas,axis=1)\n",
    "    new_B=np.zeros([M,N])\n",
    "    for i in range(M) :\n",
    "        mask=np.array([o==i for o in obs[:-1] ])*1.0\n",
    "        new_B[i,:]=(np.sum(gammas*mask, axis=1)/sumgammas)\n",
    "    \n",
    "    #Compute new A\n",
    "    sumlambd=np.sum(lambdas,axis=2)\n",
    "    new_A=sumlambd/sumgammas\n",
    "    \n",
    "    #Compute new init\n",
    "    new_init=gammas[:,0]\n",
    "\n",
    "    #Compute log likehood\n",
    "    log_lik=-1*np.sum(np.log(np.array(cs)))\n",
    "\n",
    "    return new_A,new_B,new_init,log_lik\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n",
      "0  :  -2.230909143982432\n",
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n",
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n",
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n",
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n",
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n",
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n",
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n",
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n",
      "[153 200  81  48  11 108 189  20 189  60  60  44 142  12  11 108 189  11 108 189  11 108 189  81  60  60  11 108 189  60 146 146\n",
      "  60  44 142  12 173 200  67  95 184 126 184 173 200   9  98  45  27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPad\\AppData\\Local\\Temp\\ipykernel_15824\\747337052.py:18: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  cs.append(1/c)\n",
      "C:\\Users\\ThinkPad\\AppData\\Local\\Temp\\ipykernel_15824\\747337052.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "  alpha/=c\n",
      "C:\\Users\\ThinkPad\\AppData\\Local\\Temp\\ipykernel_15824\\747337052.py:29: RuntimeWarning: invalid value encountered in multiply\n",
      "  beta=np.matmul(b[obs[T-i],:]*beta,a)\n",
      "C:\\Users\\ThinkPad\\AppData\\Local\\Temp\\ipykernel_15824\\747337052.py:37: RuntimeWarning: invalid value encountered in multiply\n",
      "  lambdas[:,:,s]=np.transpose((betas[:,s+1]*b[obs[s+1],:])*np.transpose(a*alphas[:,s]))\n"
     ]
    }
   ],
   "source": [
    "api_calls=[]\n",
    "\n",
    "with open(\"sample_analysis_data.txt\", \"r\") as f:\n",
    "    L = f.readlines()\n",
    "    for l in L :\n",
    "        api_calls.append(l.split(\" \"))\n",
    "    \n",
    "merged_api_calls = []\n",
    "for api_call in api_calls :\n",
    "    merged_api_calls+=api_call\n",
    "\n",
    "s=set(merged_api_calls)\n",
    "dict_api_calls = dict()\n",
    "for api_call,i in zip(list(s),range(len(list(s)))):\n",
    "    dict_api_calls[api_call]=i\n",
    "\n",
    "def train_HMM_on_seq_of_api_calls(line_number,n_hidden):\n",
    "    line_as_numbers=np.array([dict_api_calls[x] for x in api_calls[line_number]])\n",
    "    est_A=np.array([[.6,.2],[.4,.8],])\n",
    "    est_B=np.random.randn(2*202).reshape((202,2))\n",
    "    est_B=np.exp(est_B)\n",
    "    est_init=np.array([1,0])\n",
    "\n",
    "    for _ in range(10) :\n",
    "        est_A,est_B,est_init,log_lik=Baum_Welch_Norm_step(est_A,est_B,est_init,line_as_numbers)\n",
    "        if _%20==0 :\n",
    "            print(_, \" : \" ,log_lik)\n",
    "\n",
    "train_HMM_on_seq_of_api_calls(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 hidden states with transition matrix\n",
      "[[.7 .3]\n",
      " [.3 .7]]\n",
      "\n",
      "2 observable states with emission matrix\n",
      "[[.4 .9]\n",
      " [.6 .1]]\n",
      "\n",
      "Derived MM :\n",
      "[[.68846 .57857]\n",
      " [.31154 .42143]]\n",
      "starting with A,B, init :\n",
      "[[0.6 0.2]\n",
      " [0.4 0.8]] \n",
      "\n",
      " [[0.3 0.8]\n",
      " [0.7 0.2]] \n",
      "\n",
      " [0 1]\n",
      "let's perform 1000 Baum-Welch steps :\n",
      "\n",
      "0  :  -6408.921139171808\n",
      "20  :  -6402.39334860554\n",
      "40  :  -6402.305048381193\n",
      "60  :  -6402.238774360075\n",
      "80  :  -6402.187519175388\n",
      "100  :  -6402.146808045495\n",
      "120  :  -6402.113709352505\n",
      "140  :  -6402.086258416671\n",
      "160  :  -6402.063108872944\n",
      "180  :  -6402.043317255717\n",
      "200  :  -6402.026207323153\n",
      "220  :  -6402.011283135373\n",
      "240  :  -6401.998172506434\n",
      "260  :  -6401.986589694684\n",
      "280  :  -6401.976310457141\n",
      "300  :  -6401.967155152601\n",
      "320  :  -6401.958977144952\n",
      "340  :  -6401.951654733661\n",
      "360  :  -6401.945085454932\n",
      "380  :  -6401.939181991924\n",
      "400  :  -6401.933869188169\n",
      "420  :  -6401.929081825547\n",
      "440  :  -6401.924762938366\n",
      "460  :  -6401.920862508551\n",
      "480  :  -6401.917336435576\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 33\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDerived MM :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m     my_print(HMM_to_MM(estA,estB))\n\u001b[1;32m---> 33\u001b[0m \u001b[43mtest_Baum_Welch_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 20\u001b[0m, in \u001b[0;36mtest_Baum_Welch_norm\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms perform 1000 Baum-Welch steps :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m) :\n\u001b[1;32m---> 20\u001b[0m     estA,estB,estinit,log_lik\u001b[38;5;241m=\u001b[39m\u001b[43mBaum_Welch_Norm_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestA\u001b[49m\u001b[43m,\u001b[49m\u001b[43mestB\u001b[49m\u001b[43m,\u001b[49m\u001b[43mestinit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m20\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m :\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m ,log_lik)\n",
      "Cell \u001b[1;32mIn[23], line 30\u001b[0m, in \u001b[0;36mBaum_Welch_Norm_step\u001b[1;34m(a, b, init, obs)\u001b[0m\n\u001b[0;32m     28\u001b[0m     beta\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmatmul(b[obs[T\u001b[38;5;241m-\u001b[39mi],:]\u001b[38;5;241m*\u001b[39mbeta,a)\n\u001b[0;32m     29\u001b[0m     beta\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39mcs[T\u001b[38;5;241m-\u001b[39mi\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 30\u001b[0m     betas[:,T\u001b[38;5;241m-\u001b[39mi\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m=\u001b[39mbeta\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#Compute the lambdas\u001b[39;00m\n\u001b[0;32m     34\u001b[0m lambdas\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros([N,N,T\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_Baum_Welch_norm():\n",
    "    A=np.array([[.7,.3],[.3,.7],])\n",
    "    B=np.array([[.4,.9,],[.6,.1]])\n",
    "    print(\"2 hidden states with transition matrix\")\n",
    "    my_print(A)\n",
    "    print(\"\\n2 observable states with emission matrix\")\n",
    "    my_print(B)\n",
    "    print(\"\\nDerived MM :\")\n",
    "    my_print(HMM_to_MM(A,B))\n",
    "    init=np.array([0,1])\n",
    "    hid,obs=HMM_to_sample(A,B,0,10000)\n",
    "    A=np.array([[.6,.2],[.4,.8],])\n",
    "    B=np.array([[.3,.8],[.7,.2]])\n",
    "    print(\"starting with A,B, init :\")\n",
    "    print(A,\"\\n\\n\",B,\"\\n\\n\",init)\n",
    "    \n",
    "    estA,estB,estinit = A,B,init\n",
    "    print(\"let's perform 1000 Baum-Welch steps :\\n\")\n",
    "    for _ in range(1000) :\n",
    "        estA,estB,estinit,log_lik=Baum_Welch_Norm_step(estA,estB,estinit,obs)\n",
    "        if _%20==0 :\n",
    "            print(_, \" : \" ,log_lik)\n",
    "              \n",
    "    print(\"\\nEstimated A,B, init:\")\n",
    "    print(estA,\"\\n\\n\",estB,\"\\n\\n\",estinit)\n",
    "    print(\"\\nDerived MM :\")\n",
    "    my_print(HMM_to_MM(estA,estB))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "test_Baum_Welch_norm()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
